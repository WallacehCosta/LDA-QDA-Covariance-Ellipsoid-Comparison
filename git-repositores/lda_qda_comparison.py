# Linear and Quadratic Discriminant Analysis with Covariance Ellipsoids
# This example visualizes the covariance ellipsoids for each class and the decision
# boundaries generated by LinearDiscriminantAnalysis (LDA) and QuadraticDiscriminantAnalysis (QDA).
# Each ellipsoid represents twice the standard deviation for a given class.

# Author: Wallace de Holanda Costa
# License: MIT License

import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import colors
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.discriminant_analysis import (
    LinearDiscriminantAnalysis,
    QuadraticDiscriminantAnalysis,
)


class DiscriminantAnalysisDemo:
    """
    Encapsulates data generation, model training, and visualization
    for comparing LDA and QDA with covariance ellipsoids.
    """

    # --- Data Generation ---
    @staticmethod
    def _make_data(n_samples, n_features, cov_class_1, cov_class_2, seed=0):
        """Generates synthetic 2D Gaussian data for two classes."""
        rng = np.random.RandomState(seed)
        # Class 1: Centered at (0, 0)
        X_c1 = rng.randn(n_samples, n_features) @ cov_class_1
        # Class 2: Centered at (1, 1)
        X_c2 = rng.randn(n_samples, n_features) @ cov_class_2 + np.array([1, 1])

        X = np.concatenate([X_c1, X_c2])
        y = np.concatenate([np.zeros(n_samples), np.ones(n_samples)])
        return X, y

    def __init__(self, n_samples_shared=300, n_samples_iso=1000):
        """Initializes the three distinct datasets."""
        self.datasets = self._generate_datasets(n_samples_shared, n_samples_iso)

    def _generate_datasets(self, n_samples_shared, n_samples_iso):
        """Creates the three synthetic datasets with distinct covariance patterns."""

        # 1. Isotropic (Spherical) and Shared Covariance
        covariance_iso = np.eye(2)  # Identity matrix for isotropic covariance
        X_iso, y_iso = self._make_data(
            n_samples=n_samples_iso, n_features=2,
            cov_class_1=covariance_iso, cov_class_2=covariance_iso, seed=0,
        )

        # 2. Non-Spherical but Shared Covariance
        covariance_shared = np.array([[0.5, -0.2], [0.8, 0.5]])
        X_shared, y_shared = self._make_data(
            n_samples=n_samples_shared, n_features=2,
            cov_class_1=covariance_shared, cov_class_2=covariance_shared, seed=1,  # Changed seed
        )

        # 3. Different Covariances (Non-Shared)
        cov_c1_diff = np.array([[0.0, -1.0], [2.5, 0.7]]) * 2.0
        cov_c2_diff = cov_c1_diff.T  # Transpose for symmetry demo
        X_diff, y_diff = self._make_data(
            n_samples=n_samples_shared, n_features=2,
            cov_class_1=cov_c1_diff, cov_class_2=cov_c2_diff, seed=2,  # Changed seed
        )

        return [
            ("Isotropic & Shared Covariance", X_iso, y_iso),
            ("Shared & Elongated Covariance", X_shared, y_shared),
            ("Varying Covariances (QDA's Strength)", X_diff, y_diff),
        ]

    # --- Plotting Helpers ---
    @staticmethod
    def _plot_ellipse(mean, cov, color, ax, label=""):
        """Plots the covariance ellipsoid (2 * standard deviation) with enhanced styling."""
        v, w = np.linalg.eigh(cov)
        u = w[0] / np.linalg.norm(w[0])
        angle = np.arctan2(u[1], u[0])  # Use arctan2 for stability
        angle = 180 * angle / np.pi

        ell = mpl.patches.Ellipse(
            mean,
            2 * v[0] ** 0.5,
            2 * v[1] ** 0.5,
            angle=angle,  # Simplified angle calculation for ellipse
            facecolor=color,
            edgecolor="#1A1A1A",  # Darker, unique edge color
            linewidth=1.5,  # Slightly thinner line
            label=label
        )
        ell.set_clip_box(ax.bbox)
        ell.set_alpha(0.3)
        ax.add_artist(ell)

    def _plot_result(self, estimator, X, y, ax):
        """Plots classifier results with custom style for decision boundary and samples."""

        # Custom color map for samples
        cmap_samples = colors.ListedColormap(["#E63946", "#457B9D"])  # Custom Red/Blue

        # 1. Probability Background Fill
        DecisionBoundaryDisplay.from_estimator(
            estimator,
            X,
            response_method="predict_proba",
            plot_method="pcolormesh",
            ax=ax,
            cmap="coolwarm",  # Changed color map for background
            alpha=0.25,
        )

        # 2. Contour Line (Decision Boundary at P=0.5)
        DecisionBoundaryDisplay.from_estimator(
            estimator,
            X,
            response_method="predict_proba",
            plot_method="contour",
            ax=ax,
            colors="k",  # Black contour line
            alpha=0.9,
            levels=[0.5],
            linestyles=['--']  # Dashed line style
        )

        # 3. Sample Points
        y_pred = estimator.predict(X)
        X_right, y_right = X[y == y_pred], y[y == y_pred]
        X_wrong, y_wrong = X[y != y_pred], y[y != y_pred]

        # Correct points (smaller, lighter dots)
        ax.scatter(X_right[:, 0], X_right[:, 1], c=y_right, s=15, cmap=cmap_samples, alpha=0.6, label="Correct")

        # Wrong points (larger, darker 'X' marks)
        ax.scatter(
            X_wrong[:, 0],
            X_wrong[:, 1],
            c=y_wrong,
            s=40,  # Larger marker size
            cmap=cmap_samples,
            alpha=0.9,
            marker="X",  # Uppercase X for more visibility
            edgecolor='black',
            linewidth=0.5,
            label="Misclassified"
        )

        # 4. Class Means (Custom Star/Diamond)
        ax.scatter(
            estimator.means_[:, 0],
            estimator.means_[:, 1],
            c=["#F7A072", "#4895EF"],  # Custom colors for means
            s=250,
            marker="D",  # Diamond marker instead of star
            edgecolor="black",
            zorder=3  # Ensures means are plotted above all other elements
        )

        # 5. Covariance Ellipsoids
        if isinstance(estimator, LinearDiscriminantAnalysis):
            covariance = [estimator.covariance_] * 2
        else:
            covariance = estimator.covariance_

        # Use the modified _plot_ellipse
        self._plot_ellipse(estimator.means_[0], covariance[0], "#E63946", ax)
        self._plot_ellipse(estimator.means_[1], covariance[1], "#457B9D", ax)

        # Aesthetic configuration
        ax.set_box_aspect(1)
        ax.set(xticks=[], yticks=[])

    # --- Main Execution ---
    def run_demo(self):
        """Runs the training and plots the comparison figure."""

        # Ajusta o tamanho da figura para dar mais espaço, se necessário.
        fig, axs = plt.subplots(nrows=3, ncols=2, sharex="row", sharey="row", figsize=(10, 15))

        # Initialize the estimators
        lda = LinearDiscriminantAnalysis(solver="svd", store_covariance=True)
        qda = QuadraticDiscriminantAnalysis(store_covariance=True)

        for i, (title, X, y) in enumerate(self.datasets):
            ax_row = axs[i]

            # LDA Column
            lda.fit(X, y)
            self._plot_result(lda, X, y, ax_row[0])
            # *** SOLUÇÃO 1: Reduzir o tamanho da fonte do ylabel para evitar cortes. ***
            ax_row[0].set_ylabel(title, fontsize=10, fontweight='bold')

            # QDA Column
            qda.fit(X, y)
            self._plot_result(qda, X, y, ax_row[1])

        # Set titles
        axs[0, 0].set_title("Linear Discriminant Analysis (LDA)", fontsize=14, color="#333333")
        axs[0, 1].set_title("Quadratic Discriminant Analysis (QDA)", fontsize=14, color="#333333")

        fig.suptitle(
            "LDA vs QDA: The Impact of Covariance Assumption",
            y=0.96,
            fontsize=18,
            fontweight='bold'
        )

        # Add an overall aesthetic touch (subtly grey background)
        fig.patch.set_facecolor('#f5f5f5')

        # *** SOLUÇÃO 2: Ajustar o layout para incluir mais espaço na lateral esquerda (rect[0]) ***
        # rect=[left, bottom, right, top] -> Aumentamos a margem esquerda (left=0.08)
        plt.tight_layout(rect=[0.08, 0.03, 1, 0.95])
        plt.show()


# --- Execution Block ---
if __name__ == "__main__":
    demo = DiscriminantAnalysisDemo()
    demo.run_demo()
